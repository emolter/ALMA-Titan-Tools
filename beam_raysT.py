#!/usr/local/bin/python
'''In order to carry out spatially resolved NEMESIS retrievals with ALMA data it is necessary to correctly model the flux from Titan that lies within a single ALMA beam pointed toward an arbitrary part of Titan's disk. This program calculates the rays and weightings required to accomplish this given an elliptical beam at an arbitrary position and angle from North. The output is a .spx header to execute the averaging in NEMESIS.  This alternative version extracts a region from an ALMA image based on a supplied flux threshold. This program must be run inside CASA using execfile('beam_raysT.py') and was written based on CASA 4.5.'''
### Ned Molter 07/14/16 ###
# Modified by MAC to generate weights for arbitrary regions defined by a mask of 1's and 0's (convolved by the telescope beam). In this instance the mask is generated by the spExT percentile flux threshold algorithm.

import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from matplotlib import ticker
from scipy.signal import fftconvolve
from scipy.ndimage import zoom
from scipy.optimize import brentq

####################################################################################################
############# input parameters ########################
####################################################################################################

##### Observation Parameters #####
img = 'Titan.rest488.han.concat.clean0.image'
outfile = 'Titan.rest488.han.concat.clean0.spx'
outimg = 'beam_rays.ps' #only used if showplot = True
Titan_dist = 9.2 #au. Get from delta column in JPL Horizons
d_shift = 0. #km/s. Get from deldot column in JPL Horizons
subobslat = 24.7 #degrees. Get from Ob-lat column in JPL Horizons
ccw = 2.6 #degrees. Get from  NP.ang column in JPL Horizons - counterclockwise from north
sigma = 5.0e-3 # Spectral noise in Jy

##### Model Options #####
showplot = False #Display image of beam overlaid on Titan with latitudes as contours?
wtsCutoff = 0.0 #How small of a weighting is too small to put into the .spx header? Value between zero and 1. Value <= 0 means no cutoff. Be careful when using this - may give unexpected results - see function definition for wtsReduce routine below

##### Model Parameters #####
top_atm = 1000. + 2575. #km. Must be same as top of atmosphere in eventual NEMESIS model.
nsig_psf = 2.0 #Distance past the top of the atmosphere to include in the (square) model region, in units of sigma_psf_maj
ptile = 0.90 # Image flux threshold percentile to define extraction region
maskChan = 185 # Channel number in input image for defining extraction mask

#radii = np.asarray([0.,500.,1000.,1500.,2000.,2500.,2600.,2700.,2800.,2900.,3000.,3100.,3200.,3300.,3400.,3500.,top_atm]) #radii of annuli in km - basic accuracy
radii = np.asarray([0.,500.,1000.,1500.,2000.,2500.,2550.,2600.,2650.,2700.,2750.,2800.,2850.,2900.,2950.,3000.,3050.,3100.,3150.,3200.,3250.,3300.,3350.,3400.,3450.,3500.,top_atm]) #radii of annuli in km - better; accurate for most lines
#radii = np.asarray([0.0,500.0,1000.0,1500.0,2000.0,2500.0,2575.0,2600.0,2625.0,2650.0,2675.0,2700.0,2725.0,2750.0,2775.0,2800.0,2825.0,2850.0,2875.0,2900.0,2925.0,2950.0,2975.0,3000.0,3025.0,3050.0,3075.0,3125.0,3175.0,3225.0,3275.0,3325.0,3375.0,3425.0,3525.0,top_atm]) #radii of annuli in km - best; needed for accurate CO and HCN line wings

dx = 5. #resolution of model Titan in km. Should be << radial intervals. Runtime increases exponentially as this number decreases


#####################################################################################################
############## Function definitions ######################
#####################################################################################################

######## Functions interfacing with CASA #######

def casa_extract(img):
    #Brings image header info into script using imhead
    cubeheader = imhead(imagename=img,mode='list')
    #(beamx,beamy) = (float(cubeheader['beammajor']['value']),float(cubeheader['beamminor']['value']))
    #theta = float(cubeheader['beampa']['value']) #here theta defined as angle from north to east in degrees
    (refx,refy) = (float(cubeheader['crpix1']),float(cubeheader['crpix1'])) #center pixel
    (pixszx,pixszy) = (np.degrees(np.fabs(3600*float(cubeheader['cdelt1']))),np.degrees(np.fabs(3600*float(cubeheader['cdelt2']))))
    nspec = cubeheader['shape'][3] #number of channels
    f0 = float(cubeheader['crval4']) #reference freq in Hz
    df = float(cubeheader['cdelt4']) #channel width in Hz
    i0 = float(cubeheader['crpix4']) #reference channel usually 0
    lenx = int(cubeheader['shape'][0])
    leny = int(cubeheader['shape'][0])
    return [beamx,beamy,theta,refx,refy,pixszx,pixszy,nspec,f0,df,i0,lenx,leny]


######## Helper Functions #######
    
def jy2rad(val):
    # Find conversion from Jy/bm to radiance units
    abeam      = 2.0*np.pi*beamx*beamy/(8.0*np.log(2.0)) #beam area
    apix       = abs(pixszx*pixszy) #pixel area
    apixdeg    = apix*(1.0/3600.0)**2
    beam_per_pix = apix/abeam #number of beams per pixel
    sr_per_pix = apixdeg*(np.pi/180.0)**2 #convert to steradians
    fconv      = beam_per_pix/sr_per_pix * 1e-26 * 1e-4 * cm2hz # 1 Jy = 1e-26 W/m2/Hz, so units are eventually W/cm2/sr/cm-1
    return fconv*val

def gauss2d(x,y,fwhm_x,fwhm_y,x0,y0,theta,dx):
    #Takes in np arrays for x,y. Returns the value of the 2d elliptical gaussian. Theta defined as angle in radians from x axis to semimajor axis. dx is the pixel scale in km required for normalization
    sig_x = fwhm_x / (2*np.sqrt(2*np.log(2))) #sig is the standard deviation
    sig_y = fwhm_y / (2*np.sqrt(2*np.log(2)))
    
    # Normalize the Gaussian to unit volume by pixel number
    A = 1. / (2.*np.pi*sig_x*sig_y/dx**2)
    
    # Rotated elliptical Gaussian
    a1 = np.cos(theta)**2/(2*sig_x**2) + np.sin(theta)**2/(2*sig_y**2)
    b1 = -np.sin(2*theta)/(4*sig_x**2) + np.sin(2*theta)/(4*sig_y**2)
    c1 = np.sin(theta)**2/(2*sig_x**2) + np.cos(theta)**2/(2*sig_y**2)
    g = A*np.exp(-(a1*(x-x0)**2 - 2*b1*(x-x0)*(y-y0) + c1*(y-y0)**2))
    return g



############## The "Guts" ###############
            
def computeWeights(xcorr_km,ycorr_km,Tmask,kmpix,dx):
    """ This is where the magic happens. Builds grid representing a model Titan. Computes top-of-atmosphere emission angle at each point on the grid. Convolves this with a Gaussian beam at an arbitrary point on Titan. Computes and returns weightings to be used in .spx header. Also calculates mean lat/lon and emission angle of observation. """

    #create grid z where each point represents radius from center of Titan
    lim = kmpix * len(Tmask[0])/2.
    newxpix = int(kmpix * len(Tmask[0]) / dx)
    newypix = int(kmpix * len(Tmask[1]) / dx)
    
    # Adjust dx to match the new (integer) number of pixels
    dx = kmpix * len(Tmask[0]) / newxpix
    
    #Resample the image to the new grid
    newTmask = zoom(Tmask, (newxpix/len(Tmask[0]), newypix/len(Tmask[1])), order=1)

    x, y = np.indices(newTmask.shape)
    x = dx * (x-(x.max()-x.min())/2.0)
    y = dx * (y-(y.max()-y.min())/2.0)
    z = np.hypot(x, y)
    
    midpoints = 0.5 * (radii[1:] + radii[:-1])
     
    #Change values of z to the angles corresponding to the mid-point radii
    angles = [np.degrees(np.arcsin(float(r)/float(top_atm))) for r in midpoints] #top of atmosphere emission angle
    for i in range(len(angles)):
        z[np.logical_and(z >= radii[i], z < radii[i+1])] = angles[i]
    
    z[z >= radii[-1]] = float('NaN')

    #Make Gaussian beam
    g1 = gauss2d(x,y,a,b,0.0,0.0,theta,dx)
    
    #Convolve with image threshold mask
    g = fftconvolve(newTmask,g1,mode='same')
  
    #compute normalized weights
    wts = {}
    for val in angles:
        garr = g[np.where(z == val)]
        wts[val] = sum(garr)
    gnanarr =  g[np.where(np.isnan(z))] 
    s = sum(wts.values())
    for key,val in wts.items():
        val = float(val)/float(s)
        wts[key] = val

    meanangle = sum([val*key for key,val in wts.items()])
    print('Mean emission angle: '+str(meanangle))
        
    ########################################################################

    #Now compute mean latitude and longitude of observation

    #Finding vector of true north of Titan
    northx = -np.sin(ccw)*np.cos(subobslat)
    northy = np.cos(ccw)*np.cos(subobslat)
    northz = np.sin(subobslat) 

    with np.errstate(divide='ignore',invalid='ignore'): #We actually want all y > Titan_radius + top_atm to be nans, so the invalid inputs to arcsin are helping here
        zcoord = np.sqrt((top_atm)**2 - x**2 - y**2) #these are the actual z-coordinates (distance from Titan center to observer) at each x,y point
        dprod = (northx*x + northy*y + northz*zcoord)/(top_atm) #dot product of north pole vector and each vector in model planet
        z_lat = 90 - np.degrees(np.arccos(dprod)) #latitude of each point on the 2-d grid

    conv = np.multiply(g,z_lat)
    meanlat = np.nansum(conv)/np.nansum(g)
    print('Mean top-of-atmosphere latitude: '+str(meanlat))

    ########################################################################

    #Plots
    
    if showplot:
        # Plot beam overlaid on image of Titan with lines of latitude
        z_flat = np.copy(z)*0 + 1
        conv_flat = np.multiply(g,z_flat)
        fig2,ax = plt.subplots(figsize = (8.5,8.5))

        #Tricking the plot to turn axis labels into values of km, even though data is in terms of indices of z
        major_ticks_corrected = [-4000,-3000,-2000,-1000,0,1000,2000,3000,4000] #this is what we want them to eventually be
        major_ticks_raw = [(val + top_atm + a)/dx for val in major_ticks_corrected] #converting into the native units of the arrays z_lat and conv_flat
        ax.set_xticks(major_ticks_raw) #setting locations to those converted values
        ax.set_yticks(major_ticks_raw)

        #Plot the thing
        im = ax.imshow(conv_flat, cmap='RdBu',origin='lower') #Plot beam

        #Overlay latitudes as contours
        ctr = ax.contour(z_lat,colors='gold',linewidths=2)
        ax.clabel(ctr, inline=1, fontsize=18, fmt='%1.1f')
        for line in ctr.collections: #Making negative contours solid instead of dashed
            if line.get_linestyle() != [(None, None)]:
                line.set_linestyle([(None, None)])
        ax.legend([ctr.collections[-1]],['Top-of-Atmosphere Latitude'],loc='upper left')

        #Finish tricking the plot to turn axis labels into values of km
        ticklabels_old = ax.get_xticks().tolist()
        ticklabels = [val*dx - top_atm - a for val in ticklabels_old] #converting current tick label values back into km
        ticklabels = [str(int(val)) for val in ticklabels] #Removing decimal at end to make look nice
        ax.set_xticklabels(ticklabels,fontsize=14)
        ax.set_yticklabels(ticklabels,fontsize=14)
        ax.set_xlim([a/dx - 500/dx,(a+2*top_atm)/dx + 500/dx]) #Constrain to have only a bit of white space around Titan
        ax.set_ylim([a/dx - 500/dx,(a+2*top_atm)/dx + 500/dx])
        ax.set_xlabel('Distance from Center of Titan (km)',fontsize=16)
        ax.set_ylabel('Distance from Center of Titan (km)',fontsize=16)
        
        #Colorbar
        cbar = fig2.colorbar(im,orientation='horizontal',shrink=0.78,pad=0.1)
        cbar.ax.set_xlabel('Weighting',fontsize=18)
        cbar.ax.tick_params(labelsize=16)
        
        fig2.savefig(outimg,bbox='None')

    #Other diagnostic plots
    
    ## #Plot Gaussian
    ## fig0 = plt.figure(figsize = (15,15))
    ## ax = fig0.add_subplot(111)       
    ## ax.imshow(g,cmap='RdBu',origin='lower')
    ## plt.show()
    ## #Plot z
    ## fig1 = plt.figure(figsize = (15,15))
    ## ax = fig1.add_subplot(111)
    ## ax.imshow(z, cmap='Blues',origin='lower')
    ## plt.show()

    ## #Plot convolution
    ## z_flat = np.copy(z)*0 + 1
    ## conv_flat = np.multiply(g,z_flat)
    ## conv = np.multiply(g,z)
    ## fig2,ax = plt.subplots(figsize = (15,15))
    ## im = ax.imshow(conv_flat, cmap='RdBu',origin='lower')
    ## ctr = ax.contour(z,colors='yellow')
    ## ax.clabel(ctr, inline=1, fontsize=14, fmt='%1.1f')
    ## cbar = fig2.colorbar(im,orientation="horizontal")
    ## cbar.ax.set_xlabel('Weighting',fontsize=18)
                
    return wts,meanlat

def wtsReduce(wts,wtsCutoff):
    '''Remove any annulus with less than a given weighting. Renormalize remaining annuli by uniformly multiplying them such that they add up to the value they used to. Note this isn't the most nuanced treatment: it'd be better to "donate" the weighting of the deleted annuli to a nearby annulus, not redistribute weightings evenly.'''
    norm = np.sum(wts.values()) #the weightings may not add up to 1 at this stage because of treatment of NaN values
    wts_new = {key:wts[key] for key in wts if wts[key] >= wtsCutoff}
    renorm = norm/np.sum(wts_new.values())
    wts_new = {key:wts_new[key]*renorm for key in wts_new}
    return wts_new


def spExT(imgname,ptile,CHAN=1920,XMIN=108,YMIN=108,XMAX=148,YMAX=148,returnMask=False):
    '''Obtain spectrum within region defined by given flux threshold/percentile (ptile) in channel CHAN. Make sure the imval boundaries are reasonable before running!'''
    
    # Get image info
    cubeheader = imhead(imagename=imgname, mode="list")
    # Get the number of frequency channels
    nspec = cubeheader['shape'][3]
    # reference freq in Hz
    f0 = float(cubeheader['crval4']) 
    # channel width in Hz
    df = float(cubeheader['cdelt4']) 
    # reference pixel
    i0 = float(cubeheader['crpix4'])
    beamPix = 1./ pixBeam(imgname)

    # Generate frequency grid
    freqspec = ((np.arange(nspec) - i0) * df + f0)

    # Extract data in (default) box
    subcube = imval(imagename=imgname,box=str(XMIN)+','+str(YMIN)+','+str(XMAX)+','+str(YMAX))['data']
    
    # Take spatial slice at channel CHAN
    subcubeplane=subcube[:,:,CHAN]
    
    thresh = brentq(fluxThreshEq,np.min(subcubeplane),np.max(subcubeplane),args=(subcubeplane,ptile))
    masked = np.ma.array(subcubeplane,mask=subcubeplane<thresh)
    
    fig = plt.figure()
    fig.clf()
    ax = fig.add_subplot(1,1,1)
    ax.set_title('Extraction region')
    c = ax.imshow(masked.transpose(),origin='lower',interpolation='nearest')
    fig.show()
    
    spectrum=[]
    for i in range(len(subcube[0][0])):
        masked = np.ma.array(subcube[:,:,i],mask=subcubeplane<thresh)
        spectrum.append(masked.sum() * beamPix)
    
    
    
    if returnMask:
       return freqspec/1e9,np.asarray(spectrum),np.invert(masked.mask)*1.0
    else:
    # Return arrays of frequency in GHz and flux    
       return freqspec/1e9,np.asarray(spectrum)



######### Functions redefined to work for disk average ##########
    
def jy2rad_diskavg(val):
    # Find conversion from Jy/bm to radiance units
    abeam      = 2.0*pi*beamx*beamy/(8.0*np.log(2.0)) #beam area
    apix       = abs(pixszx*pixszy) #pixel area
    apixdeg    = apix*(1.0/3600.0)**2
    beam_per_pix = apix/abeam #number of beams per pixel
    sr_per_pix = apixdeg*(np.pi/180.0)**2 #convert to steradians
    atitan = np.pi*((beamx/a)*top_atm)**2 #in arcsec. beamx/a is just an easy way to convert km to arcsec
    titan_pix = atitan/apix
    fconv      = beam_per_pix/(titan_pix*sr_per_pix) * 1e-26 * 1e-4 * cm2hz # 1 Jy = 1e-26 W/m2/Hz, so units are eventually W/cm2/sr/cm-1
    return fconv*val
    

        
#####################################################################################################
############## Code #################
#####################################################################################################

#Define, extract, and calculate constants
lightspeed = 299792458.0 #m/s
cm2hz = 29.9792458 * 1e9

subobslat = np.deg2rad(subobslat)
ccw = np.deg2rad(ccw)

xcorr_km = 0.0
ycorr_km = 0.0

[beamx,beamy,theta,refx,refy,pixszx,pixszy,nspec,f0,df,i0,lenx,leny] = casa_extract(img) #extracting image parameters from CASA

Titan_dist = Titan_dist*149597870 #to km
theta = np.radians(theta+90) #change to what's required by computeWeights
a = Titan_dist*np.radians(np.arcsin(beamx/3600)) #major axis at half-max in km
b = Titan_dist*np.radians(np.arcsin(beamy/3600)) #minor axis at half-max in km

#Input image pixel size in km
kmpix = pixszx * a/beamx

#Beam major axis sigma in pixels 
sigmaxpix = int(a / (2*np.sqrt(2*np.log(2))) / kmpix) + 1

# Define box within which to extract spectrum and generate convolved region
top_atm_pix = int(top_atm / kmpix) + 1
xminBox = int(lenx / 2.) - top_atm_pix - (nsig_psf*sigmaxpix)
yminBox = int(leny / 2.) - top_atm_pix - (nsig_psf*sigmaxpix)
xmaxBox = int(lenx / 2.) + top_atm_pix + (nsig_psf*sigmaxpix)
ymaxBox = int(leny / 2.) + top_atm_pix + (nsig_psf*sigmaxpix)

#Extract spectrum and weights
spx = {}

#extract spectrum

(freq,flux,Tmask) = spExT(img,ptile,CHAN=maskChan,XMIN=xminBox,YMIN=yminBox,XMAX=xmaxBox,YMAX=ymaxBox,returnMask=True) 

wts,meanlat = computeWeights(xcorr_km,ycorr_km,Tmask,kmpix,dx) #compute weights
freq = freq*1e9*(d_shift*1000.+lightspeed)/lightspeed #doppler shift
freq = freq/(lightspeed*100.) #convert to cm-1 from Hz. 
flux = jy2rad(flux)

if wtsCutoff > 0:
    wts = wtsReduce(wts,wtsCutoff)
spx = (wts,freq,flux,meanlat)

#output to file in .spx format
with open(outfile,'w') as f:
    f.write(str(np.float32(2*(spx[1][1]-spx[1][0])))+'     '+str(spx[3])+'     0.0     1\n')
    f.write(str(len(spx[1]))+'\n')
    f.write(str(len(spx[0]))+'\n')
    for key,val in sorted(spx[0].items()):
        f.write('      0.00000      0.00000      %7.4f      %7.4f      180.000     %8.6f\n' %(key,key,val))
    for i in range(len(spx[1])):
        f.write('%11.9f  %12.5e  %12.5e\n' % (spx[1][i],spx[2][i],jy2rad(sigma)))
f.close()
